model:
  base_learning_rate: 1.0e-04
  base_learning_optimizer: "Adam"
  base_learning_schedule: "CosineAnnealingLR"
  target: models.clipmodels.solarclip_v2.SolarCLIP_v2
  params:
    ckpt_path: null
    base_modal_key: 'hmi_image'
    paired_modal_key: 'aia0094_image'
    token_type: 'all embedding'
    inner_loss_rate: 0.0

    base_modal_TokenizerConfig:

    paired_modal_TokenizerConfig:

    base_modal_VitConfig:
      target: models.clipmodels.modules.vit.BaseVisionTransformer
      params:
        input_dim: 8
        width: 768
        layers: 12
        heads: 8
        output_dim: 512
        token_type: 'all embedding'
        norm_type: 'bn1d'

    paired_modal_VitConfig:
      target: models.clipmodels.modules.vit.BaseVisionTransformer
      params:
        input_dim: 8
        width: 768
        layers: 12
        heads: 8
        output_dim: 512
        token_type: 'all embedding'
        norm_type: 'bn1d'

    lossconfig:
      target: models.reconmodels.autoencoder.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
      params:
        disc_conditional: false
        disc_in_channels: 1
        disc_start: 250001
        disc_weight: 0.75
        disc_num_layers: 2
        codebook_weight: 1.0
        n_classes: 8192


data:
  target: data.build.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 9
    wrap: false
    train:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 0
          - 5346720
        time_step: 1
    validation:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 5346720
          - 7452000
        time_step: 115200

lightning:

  trainer:
    accelerator: "gpu"
    devices: 4
    max_epochs: 1000

  modelcheckpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      save_last: true
      every_n_epochs: 1