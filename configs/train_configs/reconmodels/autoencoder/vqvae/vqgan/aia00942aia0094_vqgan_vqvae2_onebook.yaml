model:
  base_learning_rate: 1.0e-04
  base_learning_optimizer: "Adam"
  base_learning_schedule: "CosineAnnealingLR"
  target: models.reconmodels.autoencoder.models.vqvae.models.vqvae2a.VQVAE2
  params:
    ckpt_path: /mnt/tianwen-tianqing-nas/tianwen/ctf/solarclip/zyz_106/logs/reconmodels/autoencoder/vae/2025-02-06T14-08-10_vqgan_aia00942aia0094_vqgan_vqvae2_onebook/checkpoints/epoch=000002.ckpt
    vq_modal: aia0094_image
    in_channels: 1
    hidden_channels: 128
    res_channels: 32
    nb_res_layers: 2
    nb_levels: 3
    embed_dim: 64
    nb_entries: 8192
    scaling_rates:
      - 4
      - 4
      - 2

    lossconfig:
      target: models.reconmodels.autoencoder.modules.losses.vqperceptual.VaeLPIPSWithDiscriminator
      params:
        disc_conditional: false
        disc_in_channels: 1
        disc_start: 250001
        disc_weight: 0.75
        disc_num_layers: 2
        codebook_weight: 1.0
        n_classes: 8192



data:
  target: data.build.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 9
    wrap: false
    train:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 0
          - 5346720
        time_step: 1440
    validation:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 5346720
          - 7452000
        time_step: 115200


lightning:

  trainer:
    accelerator: "gpu"
    devices: 4
    max_epochs: 1000

  modelcheckpoint:
    target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      save_last: true
      every_n_epochs: 1