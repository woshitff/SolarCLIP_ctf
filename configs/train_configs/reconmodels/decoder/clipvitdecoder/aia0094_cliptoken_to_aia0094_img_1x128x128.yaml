# (B, 256, 768) -> (B, 1, 64, 64)
model:
  base_learning_rate: 1.0e-04
  base_learning_optimizer: "Adam"
  base_learning_schedule: "CosineAnnealingLR"
  target: models.reconmodels.decoder.clipdecoder.vitdecoder.ClipVitDecoder
  params:
    decode_modal_key: aia0094_image
    width: 768
    layers: 12
    heads: 12
    num_upblocks: 3
    out_channels: 1

    clip_config:
      target: models.clipmodels.solarclip.SolarCLIP_remove_CLS
      params:
        modal_key: aia0094_image
        solarclip_config:
          target: models.clipmodels.solarclip.SolarCLIP
          params:
            ckpt_path: "checkpoints/clipmodels/innerloss_0_allembed_epoch_340_model.pt"
            embed_dim: 768 
            vision_width: 768
            image_resolution_hmi: 1024  
            vision_layers_hmi: 12 
            vision_patch_size_hmi: 64  
            image_resolution_aia: 1024  
            vision_layers_aia: 12
            vision_patch_size_aia: 64 
            transformer_token_type: "all embedding"  
            norm_type: "bn1d"  
      lossconfig:
        target: torch.nn.Identity

data:
  target: data.build.DataModuleFromConfig
  params:
    batch_size: 128
    num_workers: 9
    wrap: false
    train:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 0
          - 5346720
        time_step: 60
    validation:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 5346720
          - 7452000
        time_step: 115200

lightning:
  trainer:
    strategy: "ddp"
    accelerator: "gpu"
    devices: 4
    benchmark: True

 