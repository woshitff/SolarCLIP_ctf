model:
  base_learning_rate: 1.0e-04
  base_learning_optimizer: "Adam"
  base_learning_schedule: "CosineAnnealingLR"
  target: models.reconmodels.ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    parameterization: "eps"
    linear_start: 0.00085
    linear_end: 0.0120
    log_every_t: 200
    timesteps: 100
    first_stage_key: "0094_image"
    cond_stage_key: "magnet_image"
    image_size: 64
    channels: 3
    cond_stage_trainable: false
    conditioning_key: crossattn
    scale_factor: 1
    monitor: val/loss_simple_ema
    use_ema: False

    unet_config:
      target: models.reconmodels.ldm.modules.diffusionmodules.dpmmodels.openaimodel.UNetModel
      params:
        image_size: 64
        in_channels: 3
        model_channels: 256
        out_channels: 3
        num_res_blocks: 2
        attention_resolutions: 
          - 8 # TOCHECK
        dropout: 0.1 
        channel_mult: 
          - 1
          - 2
          - 4
          - 4
        conv_resample: True
        dims: 2
        num_classes: null
        use_checkpoint: false
        use_fp16: false
        num_heads: 1
        num_head_channels: 1
        num_heads_upsample: -1
        use_scale_shift_norm: false
        resblock_updown: false
        use_new_attention_order: false
        use_spatial_transformer: false  # custom transformer support
        transformer_depth: 1            # custom transformer support
        context_dim: null               # custom transformer support
        n_embed: null                   # custom support for prediction of discrete ids into codebook of first stage vq model
        legacy: true


    first_stage_config:
      target: models.reconmodels.autoencoder.models.vae.CNN_VAE.CNN_VAE
      params:
        ckpt_path: "checkpoints/reconmodels/vae/0094_0094/epoch=000399.ckpt"
        input_size: 1024
        image_channels: 1
        hidden_dim: 64
        layers: 2
        kernel_sizes: 
          - 7
          - 7
        strides: 
          - 4
          - 4
        group_nums: 16
        latent_dim: 3
        loss_type: MSE
        lambda_kl: 0.1
      lossconfig:
        target: torch.nn.Identity
    
    cond_stage_config:
      target: models.reconmodels.autoencoder.models.vae.CNN_VAE.CNN_VAE
      params:
        ckpt_path: "checkpoints/reconmodels/vae/magnet_magnet/layers_2_kernel_[7, 7]_strides_[4, 4]_middle_true_hidden_dim_64_epoch_1000.pt"
        input_size: 1024
        image_channels: 1
        hidden_dim: 64
        layers: 2
        kernel_sizes: 
          - 7
          - 7
        strides: 
          - 4
          - 4
        group_nums: 16
        latent_dim: 3
        loss_type: MSE
        lambda_kl: 0.1
      lossconfig:
        target: torch.nn.Identity

data:
  target: data.build.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 9
    wrap: false
    train:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 0
          - 5346720
        time_step: 115200
    validation:
      target: data.dataset.SolarDataset.multimodal_dataset
      params:
        modal_list: 
          - 'magnet'
          - '0094'
        load_imgs: false
        enhance_list:
          - 1024
          - 0.5
          - 90
        time_interval: 
          - 5346720
          - 7452000
        time_step: 115200

lightning:
  trainer:
    strategy: "ddp"
    accelerator: "gpu"
    devices: 4
    benchmark: True

  